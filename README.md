# NLP Literature Survey

<b>Title:</b> Literature survey on Large Language Models and their comparison
 
<b>Aim:</b> The aim of this literature survey is to provide a comprehensive review of large language models in natural language processing. It will focus on analyzing the architectures, training techniques, and applications of prominent models such as GPT and BERT. The survey aims to compare the performance, limitations, and impact of these models, while identifying emerging trends and open challenges in the field.

<b>References:</b>
1. Gokul, A. LLMs and AI: Understanding Its Reach and Impact.
   https://doi.org/10.20944/preprints202305.0195.v1
3. 	Junjie Ye, Xuanting Chen, Nuo Xu, Can Zu, Zekai Shao, Shichun Liu, Yuhan Cui, Zeyang Zhou, Chao Gong, Yang Shen, Jie Zhou, Siming Chen, Tao Gui, Qi Zhang, Xuanjing Huang. A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models.
   https://doi.org/10.48550/arXiv.2303.1042

<b>Group Details:</b>
1. Om Achrekar (Roll No. 57)
2. Mitali Rawat (Roll No. 65)
3. Radha Vishwakarma (Roll No. 69)

